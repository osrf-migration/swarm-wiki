This tutorial describes how to upload a log file to Amazon's S3.

Each team should have received S3 credentials. If not, contact your team lead or Nate (nate@osrfoundation.org).

## Log files to upload

It is necessary to upload both the swarm and gazebo log files. These log files are located at:

```
~/.swarm/log/TIMESTAMP/swarm.log
~/.gazebo/log/TIMESTAMP/gzserver/state.log
```

A single run of simulation should have similar TIMESTAMPS for both log directories. Upload both log files into a directory on S3. If the timestamps differ, choose the swarm log file.

## Directory structure

All logs should be uploaded to `s3://osrf-swarm/<team>/<timestamp>`, where `<team>` is one of `[byu, gatech, nps, upenn]`, and <timestamp> is the time stamp generated by simulation (see above). The credentials provides upload access to only your team's directory.

## Install S3 command line tool

`sudo apt-get install s3cmd`

## Configure s3cmd

`s3cmd --configure`

Enter the Access Key and Secret Key. Leave other fields blank, do not test the setup, and then save the setup.

## List directory contents

```
s3cmd ls s3://osrf-swarm/<team>
```

## Upload a log file

```
s3cmd sync <your_file> s3://osrf-swarm/<team>/<timestamp>/
```

Make sure you end the `s3` path with a forward slash to create a directory.

In general, you should upload both `~/.gazebo/log/<timestamp>/gzserver/state.log` and `~/.swarm/log/<timestamp>/swarm.log`.  See the [tutorial on logging](https://bitbucket.org/osrf/swarm/wiki/Tutorial_9-Logging) for more information.

